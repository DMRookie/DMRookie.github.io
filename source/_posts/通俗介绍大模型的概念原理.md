---
title: 通俗介绍大模型的概念原理
date: 2025-03-22 23:33:56
tags: 大模型
---

## 大模型的爆火

近年来，大模型在人工智能领域取得了显著进展。从 ChatGPT 的横空出世到 DeepSeek 的迅速崛起，AI 正在重塑各行各业的未来。其中，DeepSeek凭借低成本、高性能以及开源策略，迅速成为行业焦点。随着其广泛应用，DeepSeek成功破圈，进入更大众的视野，使AI技术逐渐平民化。

现在去网上搜索与大模型相关的报道，会发现大模型好像无所不能。大模型既可以当医生，也可以开发游戏赚钱，还可以做数据分析和音乐生成，好像是一个全能型选手。然而，实际去使用大模型的时候，又会发现它其实是有所不能的。比如这里，图中画了一个五环，问大模型有几个圆圈，他数成6个，让他再确认，也还是6个。这里让他把撒哈拉沙漠倒过来写，他会漏掉一个哈字。最后问他哪吒2的票房排多少，它也不知道。但是这些任务对人类来说，其实并不难。那么为什么大模型会呈现这种两级分化的现象呢？这就要从大模型的原理概念说起。

![模型爆火](https://dmrookie-1304531716.cos.ap-guangzhou.myqcloud.com/techblog/imgs/20250323091551228.webp)

## 大模型的定义

来看下大模型的定义。首先什么叫模型呢？笔者有一个2岁的女娃，每天都很调皮。有一天我心血来潮，想算算她以后会长多高。那么按常识来说，女儿的身高是会遗传到父母的。因此，可以写一个简单的公式：女儿的身高=W1 * 父亲的身高 + W2 * 母亲的身高。这个公式就可以叫做一个模型。

![女儿身高](https://dmrookie-1304531716.cos.ap-guangzhou.myqcloud.com/techblog/imgs/20250323092907536.webp)

这其中，女儿的身高是我们要预测的目标，w1和w2叫作参数，那么这两个参数的具体值要怎么求呢？我们可以收集到一堆父母和女儿的实际身高数据，然后从这堆数据里面来学习，这堆数据叫做训练集。那么怎么学呢？我们一开始可以随机给w1和w2赋一个值。取多少合适呢？是不是各自取0.5，比较合适，就是一半身高来自父亲，一半来自母亲。但这里为方便理解，先各设为1。然后从训练集里抽一组数据，比如父亲身高1.8米，母亲身高1.6米，女儿身高1.63米。将父亲母亲身高带入公式，预测女儿的身高是3.4米，比女儿的实际身高大很多。此时，可以调低w1和w2的值，如调为0.5，并更新公式。接着，再随机抽一组数据进行验证校准。这个过程称为模型训练，可以重复进行多轮，直至预测结果和实际值的误差较小。最终可以求得w1=0.46，w2=0.5，这个是模型文件。

![模型训练](https://dmrookie-1304531716.cos.ap-guangzhou.myqcloud.com/techblog/imgs/20250323154803844.webp)

那么大模型的大指什么呢？首先是参数规模大，例子里只有2个参数，而大模型的参数量是非常大的，比如DeepSeek V3的参数规模是6710亿。其次是训练数据大，DeepSeek V3的训练数据达到14.8万亿。 最后是需要耗费的计算资源大，训练一个DeepSeek V3，需要557.6万美元，以当前的汇率换算，大概可以买76辆的小米SU7 Ultra。

![参数规模大](https://dmrookie-1304531716.cos.ap-guangzhou.myqcloud.com/techblog/imgs/20250323160103744.webp)

## 大模型的训练

大模型的训练分为4个阶段，预训练，有监督微调，偏好建模和强化学习。预训练是其中训练成本最大，最耗时的阶段。在这一阶段中，训练集是从网上收集到的各种资料，比如维基百科，书籍、代码等等。训的模型是一个叫Transform架构的模型。预测目标是下一个词元，可以近似理解为下一个字。中间的产出叫做基础模型，大模型的所有知识基本就是存在这个基础模型内。但这个模型只有续写能力，没有对话能力。这就像有人收集了网上所有文本，然后关起门来，每天对一只鹦鹉不停地念收集到的文本。最终，当鹦鹉听到“鹅，鹅，鹅”后，会接“曲项向天歌”。但你问鹦鹉“鹅，鹅，鹅是哪首古诗”，它也只会回“曲项向天歌”。

![大模型的训练](https://dmrookie-1304531716.cos.ap-guangzhou.myqcloud.com/techblog/imgs/20250323160212273.webp)

为了教会大模型对话能力，在有监督微调阶段，会人为的造一批高质量的问答对。然后同样用预测下一个词元的方式，教大模型学会对话。但是造问答对的成本很高，要先想到一个好的问题，再写出好的答案。所以在偏好建模阶段，训了另外一个模型。给这个模型一个问题和多个答案，奖励模型能判断哪个答案质量更好。这样到了最后的强化学习阶段，当大模型在回答问题时，可以用第三步的奖励模型来评估答案的质量，如果质量不高，就让大模型重新生成，以此来优化大模型。通过这些步骤，大模型就从一个文本续写器，变成一个能对话的智能助手。
